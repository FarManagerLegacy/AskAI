<!--HLF:
     Language = Russian,Russian (Русский);
     PluginContents = Ask AI;
    TopicHeading = h6;
    Margin = 1;
    IndentCode = 4;
     IndentList = 0;
    IndentPara = 0;
    IndentQuote = 4;
    PlainCode = false;
    PlainHeading = false;
    CenterHeading = false;
     EmptyLinesBeforeTopic = 2;
    EmptyLinesAfterHeading = 1;
     EmptyLinesBeforeHeading = 2;
    HighlightListBullet = true;
    HighlightListNumber = true;
-->

<!--
.Options CtrlStartPosChar=^|
v0.1
-->

Ask AI -- макрос для взаимодействия с ChatGPT (и другими LLM-сервисами) в FAR {#Contents refsTitle="Основные функции"}
=============================================================================

Этот макрос -- дальнейшее развитие **bito.ai code assistant** ([см.](https://forum.farmanager.com/viewtopic.php?t=13283)),
с поддержкой множества LLM-сервисов.

Доступ к сервисам реализуется как посредством (произвольных) консольных утилит,
так напрямую через REST API.

Каждый из LLM-сервисов имеет свои достоинства и недостатки, [выбор][Обзор конфигураций] остаётся за пользователем.

Макрос назначен на `Ctrl+B`. Также может быть запущен в качестве скрипта [LuaShell].

`Ctrl+B:Double` позволяет в любой момент открыть окно с выводом повторно.

_Функции:_

- Ввод __запроса__ в диалоге, ранее набранные приглашения доступны в истории поля ввода.
- Вместе с запросом передаётся __выделенный в редакторе текст__.  
  Если в запросе присутствует шаблон `{{%input%}}`, то он заменяется выделенным текстом.  
  В противном случае выделенный в редакторе текст добавляется в конец запроса.

В __диалоге__ доступны такие настройки:

- Возможность работы __в единой сессии__, с учётом предыдущего контекста.  
  По умолчанию (состояние `[?]`) сессия продолжается пока открыт редактор с выводом.  
  Сессию также можно в любой момент принудительно __очистить__ кнопкой "`-`".
- __Форматирование вывода__ по заданной границе, или по ширине окна (состояние `[?]`).  
  Блоки кода не форматируются.
- Установка различных __параметров__ генерации (в зависимости от выбранного сервиса/утилиты).  
  Значения запоминаются в истории, и легко доступны для повторного выбора.  
  Некоторые параметры специфичны для отдельной __конфигурации__, другие могут разделяться между разными
  (посредством общей истории).
- Возможность установки __переменных окружения__, необходимых для отдельных утилит.

Кнопки:

- `[ Utility cfg ]` доступна в случае, если используемая активной конфигурацией утилита
  держит __настройки в собственном файле__; нажатие кнопки позволяет открыть его в редакторе.
- `[ Definition ]` открывает в редакторе файл __определения__ активной конфигурации (\*.lua.cfg),
  например при необходимости там легко изменить набор доступных параметров.
- `[ Presets - F5 ]` позволяет подставить сразу несколько параметров набором ("пресетом").  
  По нажатию кнопки открывается [Список пресетов].
- `[ Models - F6 ]` запрашивает список __моделей__ через API, если это предусмотрено конфигурацией,
  в противном случае кнопка недоступна.  
  Также фиксированный список моделей может быть уже предварительно занесён в историю поля ввода
  (актуально для некоторых пресетов и конфигураций).
- `[ Switch ]` или же повторное нажатие `Ctrl+B` позволяет переключиться на другую конфигурацию,
  открывая [Меню выбора конфигурации].
- `{ Go! }` запуск генерации ответа модели, вывод открывается в редакторе.

Дополнительные шорткаты:

- `Shift+F4` - задать заголовки запроса (для _OpenAI-compatible_), в виде таблицы Lua или Moonscript
  (удобно использовать _[single line table literal](https://moonscript.org/reference/#the-language/table-literals)_).
- `Shift+F5` - открыть историю поля `apibase`.
- `Shift+F6` - открыть историю списка моделей.

- - -

Макросы, активные в _окне с выводом_:

- `Ctrl+Shift+Ins`:
  - скопировать выделенный текст, склеив свёрнутые строки обратно в параграфы;
  - при отсутствии выделения ищет и обрабатывает блок кода под курсором.
- `Alt+F2` полностью убрать форматирование (свёртку).

[Диалог]: #Contents


Работа с пресетами {#Presets}
------------------

Список пресетов вызывается из [диалога][Диалог] нажатием соответствующей кнопки, хоткеем, или же по `F5`.

"Пресет" представляет собой именованный набор параметров, подставляемых в соответствующие поля диалога.  
Пресеты хранятся в файлах `*.preset` и являются Lua-файлами.

Создать новый пресет можно нажав `Shift+F4` или `Ins`.

Над пресетами в списке доступны следующие действия:

- `Enter` - заполнить поля диалога значениями из пресета.
- `F4` - открыть в редакторе.
- `F5` - скопировать, `F6` - переименовать.
- `F8` или `Del` - удалить.

В списке отображаются только пресеты, подходящие для текущей конфигурации диалога:  
если в пресете содержится параметр, не имеющий соответствия в диалоге текущей конфигурации,
то такой пресет показан не будет.

Нажатием `Ctrl+H` можно принудительно отобразить все пресеты.

См. также: обзор пресетов для сервисов совместимых с __OpenAI API__ в разделе [Обзор конфигураций].

[Список пресетов]: #Presets


Установка {#Install}
=========

- Содержимое архива разместить в отдельной директории, где-то в `Macros/scripts`.
- Для [LuaShell] -- стандартным образом, т.е. где-то в `Macros/utils`,
  или в любой другой директории, доступной через `%PATH%`.
- Для работы с сетью непосредственно, через "нативные" конфигурации, такие как `openai.lua.cfg`,
  необходимы следующие модули:
    - `LuaSocket`, `LuaSec`: https://github.com/FarManagerLegacy/LuaBinaries/releases  
      и их зависимости: [OpenSSL], (для некоторых билдов) [MS Visual C++ Redist].
    - Практически любой JSON модуль, предоставляющий функции `encode`/`decode`.  
      - По умолчанию ищется модуль с одним из имён: `cjson`, `rsjson`, `ljson`, `dkjson`, `lunajson`, или просто [`json`]
        (см. также [lua-users wiki]).  
        Мною тестировались [Lua CJSON][LuaBinaries] и [`dkjson`].
      - Для явного указания имени модуля следует использовать опцию `json_module` в начале скрипта.  
        Её можно изменить прямо в коде, либо воспользоваться возможностями [ScriptsBrowser]/`cfgscript`.
- Также можно работать через сторонние утилиты:
  - Для запуска утилит рекомендуется модуль [Piper](https://forum.farmanager.com/viewtopic.php?p=167895#p167895)
    (положить в `modules`).  
    В случае его отсутствия для запуска будет использована стандартная функция [`io.popen`], в сочетании  
    с созданием временных файлов, и перенаправлением их в стандартный ввод посредством команд shell.
  - В `%PATH%` должны быть __утилиты__, соответствующие имеющимся файлам __определений__ (\*.lua.cfg),
    см. раздел [Меню выбора конфигурации].


Настройка
---------

Большая часть _конфигураций_ требует задания некоторых параметров в [диалоге][Диалог].  
Наиболее важные параметры - такие как `apibase`, `apikey` и `model` - определяются выбранным [провайдером][Обзор конфигураций].

Некоторые _утилиты_ используют файл настройки, доступный как из **диалога**, так и в [списке конфигураций][Меню выбора конфигурации]
(подробнее см. в документации соответствующих утилит).

[Установка]: #Install
[Настройка]: #Install
[LuaShell]: https://forum.farmanager.com/viewtopic.php?f=15&t=10907
[`io.popen`]: https://www.lua.org/manual/5.1/manual.html#pdf-io.popen
[OpenSSL]: https://slproweb.com/products/Win32OpenSSL.html
[MS Visual C++ Redist]: https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170#latest-microsoft-visual-c-redistributable-version
[ScriptsBrowser]: https://forum.farmanager.com/viewtopic.php?f=15&t=10418
[LuaBinaries]: https://github.com/FarManagerLegacy/LuaBinaries/
[`dkjson`]: http://dkolf.de/dkjson-lua/
[`json`]: https://luarocks.org/search?q=json
[lua-users wiki]: http://lua-users.org/wiki/JsonModules


Меню выбора конфигурации {#UtilitiesMenu}
========================

В комплекте идут __определения__ для ряда опробованных мной утилит/сервисов
(но легко добавить и новые).

С некоторыми соображениями по выбору конфигурации можно ознакомиться в разделе [Обзор конфигураций].

- Выбор конфигурации осуществляется через __меню__, доступное как прямо из [диалога][Диалог],
  так и отовсюду посредством макроса.  
  Выбор запоминается.
- Верхний раздел списка содержит "нативные" конфигурации, работающие с сетью средствами Lua.  
  Раздел не будет отображаться, если отсутствуют необходимые модули, см. [Установка].
- Нижний раздел списка содержит определения, использующие внешние утилиты.  
  По умолчанию список содержит только установленные утилиты, полный список -- по `Ctrl+H`.
  - Утилиты необходимо скачать самостоятельно (соответствующий сайт открывается по `Alt+F1` из меню).
  - Утилитам может требоваться настройка (помимо параметров в диалоге),
    подробнее см. в собственной их документации.  
    Быстрый доступ к файлу с настройками (если применимо) - `F4` в меню, или по кнопке в [диалоге][Диалог].
- По `Alt+F4` - быстрый доступ к файлу с __определением__ той или иной конфигурации (\*.lua.cfg).

В общем случае следует отдать предпочтение "нативным" конфигурациям, поскольку они обеспечивают больше возможностей.

Однако в некоторых случаях может оказаться проще или удобнее работать и через утилиты, например:

- если соответствующая утилита уже есть (и используется из командной строки);
- если утилита уже содержит настройки провайдеров (как `bito`, `tgpt`, `pytgpt`);
- если пользователю проще скачать утилиту, чем выполнить другие инструкции по [установке][Установка].


Обзор утилит
------------

- [gh models] - GitHub Models extension.  
  Инструкуции по установке см. на домашней странице.
  Необходим аккаунт GitHub. Действуют [лимиты](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits).
- [tgpt], [pytgpt] - не требуют предварительной настройки.  
  Недостаток: не гарантирована стабильность (иногда требуется обновление утилит).
- [bito] настройка описана [тут](https://forum.farmanager.com/viewtopic.php?t=13283).  
  Недостаток: бесплатный лимит 20 сообщений в день.
- Прочие утилиты - [aichat], [chatgpt-cli], [mods], [sgpt] - работают с [OpenAI API] (и совместимыми).  
  Требуют задания некоторых параметров, прежде всего `apibase`, `apikey`, и `model`.
  Их значения зависят от выбранного [провайдера][Обзор конфигураций].  
  В зависимости от утилиты, параметры надо установить или через файл настроек
  (`F4` в списке [выбора](#UtilitiesMenu)),
  или как __аргументы__ командной строки (доступные в [диалоге][Диалог]),
  или через __переменные окружения__ (также доступны в [диалоге][Диалог]).

[gh models]: https://github.com/github/gh-models
[tgpt]: https://github.com/aandrew-me/tgpt
[pytgpt]: https://github.com/Simatwa/python-tgpt
[bito]: https://bito.ai/
[aichat]: https://github.com/sigoden/aichat
[chatgpt-cli]: https://github.com/kardolus/chatgpt-cli
[mods]: https://github.com/charmbracelet/mods
[sgpt]: https://github.com/tbckr/sgpt
[OpenAI API]: https://platform.openai.com/docs/api-reference


Обзор конфигураций {#Providers}
==================

Выбор модели
------------

На данный момент наиболее сильные модели это:

- `o3`, `o1` и `gpt-4o` от [OpenAI];
- `gemini-2.0-pro` от [Google];
- `claude-3.7-sonnet` от [Anthropic];
- `grok-3` от [xAI];

Из опенсорсных - все что побольше, например:

- из серии [Llama] от __Meta AI__: `llama-3.1-405b`, `llama-3.2-90b`, `llama-3.3-70b`;
- ряд моделей от китайских разработчиков также демонстрирует хорошие результаты:
  [DeepSeek], [Qwen], _Yi_ от [01.AI], [MiniMax].

Ориентироваться можно по рейтингу [ChatBot Arena](https://lmarena.ai/?leaderboard).

[OpenAI]: https://platform.openai.com/
[Google]: https://ai.google.dev/
[Anthropic]: https://www.anthropic.com/
[xAI]: https://x.ai/grok
[Llama]: https://www.llama.com/
[DeepSeek]: https://www.deepseek.com/
[Qwen]: https://qwenlm.github.io/
[01.AI]: https://www.01.ai/
[MiniMax]: https://www.minimaxi.com/en


Обзор провайдеров
-----------------

- [OpenAI] -- оригинальный разработчик _ChatGPT_.  
  Новому пользователю предоставляется кредит $5, после исчерпания которого доступно только платное использование.  
  Работа с этим апи возможна как с помощью сторонних утилит, так и с помощью "нативной" конфигурации,
  так и называющейся "_OpenAI-compatible_".
- Другие _OpenAI_-совместимые: [Mistral AI], [xAI] _Grok_, [AI21 labs] _Jamba_.  
  К этой же категории относится целый ряд провайдеров, предоставляющие доступ к OpenSource-моделям.
- Провайдеры с собственным API, такие как [Google] _Gemini_, [Anthropic] _Claude_, [Cohere] _Command R+_, и т.д.  
  Для поддержки в _AskAI_ требуется или соответствующая "нативная" конфигурация, или специальный
  сервис-адаптер, который будет конвертировать API в совместисый с _OpenAI_ формат.  
  Примеры таких сервисов: [openai-gemini], [openai-github-copilot], и др.

[Mistral AI]: https://mistral.ai/
[AI21 labs]: https://www.ai21.com
[Cohere]: https://cohere.com/command
[openai-gemini]: https://habr.com/ru/articles/798123/
[openai-github-copilot]: https://habr.com/ru/articles/799215/


Обзор [пресетов][Список пресетов] для сервисов совместимых с [OpenAI API]
-------------------------------------------------------------------------

В комплекте со скриптом идёт набор пресетов, содержащих предварительно заданные
значения `apibase` (и начальное значение `model`).  
В большинстве случаев пользователю также требуется самостоятельно получить `apikey`,
адрес сайта для регистрации можно найти в файле пресета (открывается из списка по `F4`).

С перечисленными ниже пресетами помимо конфигурации `openai.lua.cfg` совместимы также
конфигурации некоторых утилит (кроме тех, которые хранят эти значения в собственных файлах настроек).

- Не требуют ключа (`apikey`) только эти пресеты:
   - [anyai]\: контекст лимитирован
   - `tmrace`: лимит 50 сообщений в сутки
   - [deepinfra] (всевозможные OpenSource модели): some anonymous usage allowed
- Для использования других надо зарегистрироваться и получить ключ.
  Следующие пресеты относятся к бесплатным сервисам (с определёнными лимитами):
   - [cloudflare] (в основном небольшие модели, но есть и `@cf/meta/llama-3.3-70b-instruct-fp8-fast`)
   - [gemini] от Google
   - [github] (модели от _OpenAI_, _DeepSeek_, _Anthropic_, _Mistral_, _Meta_, _Cohere_, _AI21_, _Microsoft_ и др.)
   - [groq] (модели до 90b)
   - [mistral], [codestral]
   - [sambanova] (Llama <= 405b)
- На некоторых сервисах только часть моделей доступно бесплатно:
   - [chutes] (DeepSeek, Llama, Qwen, ...)
   - [huggingface] (бесплатно в основном небольшие модели, но есть и такие как `CodeLlama-34b-Instruct-hf` и `Qwen2.5-72B-Instruct`)
   - [openrouter] (бесплатно в основном небольшие модели, но доступны и такие как `llama-3.1-405b-instruct`)
   - [siliconflow] (бесплатно - небольшие модели)
   - [together.ai] (бесплатно - `meta-llama/Llama-3.3-70B-Instruct-Turbo-Free`, `meta-llama/Llama-Vision-Free`, `deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free`)
- Некоторые сервисы дают возможность бесплатно пользоваться только сайтом, но в некоторых случаях возможно
  задействовать их приватный API (указав Cookie и/или другие требуемые данные в заголовках):
   - [cerebras] (`llama-3.3-70b`, `llama3.1-70b`, `llama3.1-8b`, `deepseek-r1-distill-llama-70b`)
   - [featherless] (бесплатно - небольшие модели)
   - [fireworks.ai] (всевозможные OpenSource-модели)
   - [lepton] (всевозможные OpenSource-модели)
- Для полноты: пресеты для некоторых сервисов, для которых доступны пробные ключи:
   - [ai21] (Jamba): $10 credit, 3mo trial?
   - [deepbricks] (o1/gpt-4o/3.5/claude-3.5-sonnet/llama): allows some usage with 0 balance
   - [grok] от [xAI]
   - [hyperbolic] (OpenSource-модели: DeepSeek, Llama, Qwen): $10 credit for free trial
   - [ncompass] (OpenSource-модели: Llama, Qwen, ...): $100 of credit
   - [novita.ai] (OpenSource-модели): $0.5 credit

Кроме того:

- `copilot-`/`gemini-proxy-public` позволяют попробовать соответствующие сервисы-адаптеры, упомянутые выше.  
  Примечание: `gemini` [с некоторых пор](https://developers.googleblog.com/en/gemini-is-now-accessible-from-the-openai-library/)
  доступен и через OpenAI API.
- `keepass` позволяет держать свои собственные пресеты в базе [KeePass](https://keepass.info/).  
  Подобным образом можно организовать работу и с другими аналогичными утилитами.

[ai21]: https://www.ai21.com/jamba
[anyai]: https://api.airforce/
[cerebras]: https://cloud.cerebras.ai/
[chutes]: https://chutes.ai/app
[codestral]: https://console.mistral.ai/codestral
[cloudflare]: https://developers.cloudflare.com/workers-ai/models/
[deepbricks]: https://deepbricks.ai/pricing
[deepinfra]: https://deepinfra.com/models/text-generation
[featherless]: https://featherless.ai/models
[fireworks.ai]: https://fireworks.ai/models
[gemini]: https://ai.google.dev/gemini-api/docs/openai
[github]: https://github.com/marketplace/models/
[grok]: https://console.x.ai/
[groq]: https://console.groq.com/playground
[huggingface]: https://huggingface.co/models?other=text-generation-inference&inference=warm
[hyperbolic]: https://app.hyperbolic.xyz/models
[lepton]: https://www.lepton.ai/playground
[mistral]: https://docs.mistral.ai/getting-started/models/models_overview/
[ncompass]: https://www.ncompass.tech/about
[novita.ai]: https://novita.ai/model-api/product/llm-api
[openrouter]: https://openrouter.ai/models?q=:free
[sambanova]: https://cloud.sambanova.ai/pricing
[siliconflow]: https://docs.siliconflow.cn/reference/chat-completions-1
[together.ai]: https://api.together.xyz/models

- - -

**Примечание**: задача перечислить все существующих сервисы не ставилась, это попросту невозможно,
не говоря о том что каждый день могут появляться новые.

Помимо самостоятельных провайдеров, можно встретить также сервисы не вполне понятного происхождения,
не имеющие даже официального сайта. Такими в списке выше являются `anyai` и `tmrace`.

По причине их неопределённого статуса пользоваться ими следует с осторожностью, и не передавать чувствительные данные!

Подобных сервисов довольно много, некоторые например перечислены тут: [cool ai stuff!](https://cas.zukijourney.com/)

---
refsTemplate: refsBottom
links: https://github.com/FarManagerLegacy/AskAI | [Скачать](https://github.com/FarManagerLegacy/AskAI/zipball/master)
...
