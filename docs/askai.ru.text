<!--HLF:
     Language = Russian,Russian (Русский);
     PluginContents = Ask AI;
    TopicHeading = h6;
    Margin = 1;
    IndentCode = 4;
     IndentList = 0;
    IndentPara = 0;
    IndentQuote = 4;
    PlainCode = false;
    PlainHeading = false;
    CenterHeading = false;
     EmptyLinesBeforeTopic = 2;
    EmptyLinesAfterHeading = 1;
     EmptyLinesBeforeHeading = 2;
    HighlightListBullet = true;
    HighlightListNumber = true;
-->

<!--
.Options CtrlStartPosChar=^|
v0.1
-->

Ask AI -- макрос для взаимодействия с ChatGPT (и другими LLM-сервисами) в FAR {#Contents refsTitle="Описание"}
=============================================================================

Этот макрос -- дальнейшее развитие **bito.ai code assistant** ([см.](https://forum.farmanager.com/viewtopic.php?t=13283)),
теперь с поддержкой множества LLM-сервисов.

Доступ к сервисам возможен как посредством разнообразных консольных утилит, так и напрямую через REST API.

Каждый из LLM-сервисов имеет свои достоинства и недостатки, [выбор][Обзор конфигураций] -- за пользователем.

Макрос назначен на `Ctrl+B`, и открывает [диалог] для ввода запроса и настройки параметров генерации.
При этом выделение редактора передаётся в качестве контекста.

Может быть также запущен в качестве скрипта [LuaShell].

_Вывод_ ответа осуществляется в отдельном редакторе.

> Макросы, активные в окне с выводом:
>
> - `Ctrl+Shift+Ins`:
>   - скопировать выделенный текст, склеив свёрнутые строки обратно в параграфы;
>   - при отсутствии выделения ищет и обрабатывает блок кода под курсором.
> - `Alt+F2` полностью убрать форматирование (свёртку).

`Ctrl+B:Double` позволяет в любой момент открыть окно с выводом повторно.

**Примечание**: составные сочетания типа `Ctrl+B:Double` предполагают использование модуля [MacroEx].  
Альтернативно, можно заменить сочетание на простое, через параметр `keyOutput`.  
Его можно изменить прямо в коде (в начале скрипта), либо воспользоваться возможностями [ScriptsBrowser]/`cfgscript`.

[Вывод]: #Contents
[MacroEx]: https://forum.farmanager.com/viewtopic.php?f=15&t=8764


Диалог {#Dialog}
======

Диалог служит для ввода __запроса__ и настройки различных параметров.  
Ранее набранные приглашения доступны в истории поля ввода.  
Для удобного редактирования объёмных/многострочных запросов рекомендуется макрос
[EditBoxToEditor](https://forum.farmanager.com/viewtopic.php?p=178783#p178783).

Вместе с запросом передаётся __выделенный в редакторе текст__.  
Если в запросе присутствует шаблон `{{%input%}}`, то выделенный текст подставляется на его место.  
В противном случае выделенный текст добавляется в конец запроса.

Последующие запросы учитывают предыдущий контекст, образуя диалог (_сессию_), если не настроено иное.

Доступны такие __настройки__:

- `Session` - по умолчанию (состояние `[?]`) сессия продолжается, пока открыт редактор с [выводом][вывод].  
  Также сессию можно в любой момент принудительно __очистить__ кнопкой "`-`".
- __Форматирование вывода__ по заданной границе, или по ширине окна (состояние `[?]`).  
  Блоки кода не форматируются.
- Установка различных __параметров__ генерации (в зависимости от выбранного сервиса/утилиты).  
  Значения запоминаются в истории и легко доступны для повторного выбора.  
  Некоторые параметры специфичны для отдельной __конфигурации__, другие могут разделяться между разными
  (посредством общей истории).
- Возможность установки __переменных окружения__, необходимых для отдельных утилит.

__Кнопки__:

- `[ Utility cfg ]` доступна в случае, если используемая активной конфигурацией утилита
  держит __настройки в собственном файле__; нажатие кнопки позволяет открыть его в редакторе.
- `[ Definition ]` открывает в редакторе файл __определения__ активной конфигурации (\*.lua.cfg),
  например при необходимости изменить набор доступных параметров.
- `[ Presets - F5 ]` позволяет подставить сразу несколько параметров набором ("пресетом").  
  По нажатию кнопки открывается [Список пресетов][Пресеты].
- `[ Models - F6 ]` запрашивает список __моделей__ через API, если это предусмотрено конфигурацией,
  в противном случае кнопка недоступна.  
  Также фиксированный список моделей может быть уже предварительно занесён в историю поля ввода
  (актуально для некоторых пресетов и конфигураций).
- `[ Switch ]` или же повторное нажатие `Ctrl+B` позволяет переключиться на другую конфигурацию,
  открывая [Меню выбора конфигурации].
- `{ Go! }` или `Enter` -- запуск генерации ответа модели, [вывод] открывается в отдельном редакторе.

Дополнительные шорткаты:

- `Shift+F4` - задать заголовки запроса (для _OpenAI-compatible_), в виде таблицы Lua или Moonscript
  (удобно использовать _[single line table literal](https://moonscript.org/reference/#the-language/table-literals)_).
- `Shift+F5` - открыть историю поля `apibase`.
- `Shift+F6` - открыть отсортированный в алфавитном порядке список истории моделей.


Работа с пресетами {#Presets}
------------------

**Список пресетов** вызывается из [диалога][Диалог] нажатием соответствующей кнопки, хоткеем, или же по `F5`.

"Пресет" представляет собой именованный набор параметров, подставляемых в соответствующие поля диалога.  
Пресеты хранятся в файлах `*.preset` и являются Lua-файлами.

Создать новый пресет можно нажав `Shift+F4` или `Ins`.

Над пресетами в списке доступны следующие действия:

- `Enter` - заполнить поля диалога значениями из пресета.
- `F4` - открыть в редакторе.
- `F5` - скопировать, `F6` - переименовать.
- `F8` или `Del` - удалить.

В списке отображаются только пресеты, подходящие для текущей конфигурации диалога:  
если в пресете содержится параметр, не имеющий соответствия в диалоге текущей конфигурации,
то такой пресет показан не будет.

Нажатием `Ctrl+H` можно принудительно отобразить все пресеты.

См. также: обзор пресетов для сервисов совместимых с __OpenAI API__ в разделе [Обзор конфигураций].

[Пресеты]: #Presets


Установка {#Install}
=========

- Содержимое архива разместить в отдельной директории, где-то в `Macros/scripts`.
- Для [LuaShell] -- стандартным образом, т.е. где-то в `Macros/utils`,
  или в любой другой директории, доступной через `%PATH%`.
- Для работы с сетью непосредственно, через "нативные" конфигурации, такие как `openai.lua.cfg`,
  необходимы следующие модули:
    - `LuaSocket`, `LuaSec`: https://github.com/FarManagerLegacy/LuaBinaries/releases  
      и их зависимости: [OpenSSL], [MS Visual C++ Redist].
    - Практически любой JSON модуль, предоставляющий функции `encode`/`decode`.  
      - По умолчанию ищется модуль с одним из имён: `cjson`, `rsjson`, `ljson`, `dkjson`, `lunajson`, или просто [`json`]
        (см. также [lua-users wiki]).  
        Мною тестировались [Lua CJSON][LuaBinaries] и [`dkjson`].
      - Для явного указания имени модуля следует использовать опцию `json_module` в начале скрипта.  
        Её можно изменить прямо в коде, либо воспользоваться возможностями [ScriptsBrowser]/`cfgscript`.
- Также можно работать через [сторонние утилиты][Обзор утилит]:
  - Для запуска утилит рекомендуется модуль [Piper](https://forum.farmanager.com/viewtopic.php?p=167895#p167895)
    (положить в `modules`).  
    В случае его отсутствия для запуска будет использована стандартная функция [`io.popen`], в сочетании  
    с созданием временных файлов, и перенаправлением их в стандартный ввод посредством команд shell.
  - В `%PATH%` должны быть __утилиты__, соответствующие имеющимся файлам __определений__ (\*.lua.cfg),
    см. раздел [Обзор утилит].


Настройка
---------

Большая часть _конфигураций_ требует задания некоторых параметров в [диалоге][Диалог].  
Наиболее важные параметры - такие как `apibase`, `apikey` и `model` - определяются выбранным [провайдером][Обзор конфигураций].

Некоторые _утилиты_ используют файл настройки, доступный как из **диалога**, так и в [списке конфигураций][Меню выбора конфигурации]
(подробнее см. в документации соответствующих утилит).

[Установка]: #Install
[Настройка]: #Install
[LuaShell]: https://forum.farmanager.com/viewtopic.php?f=15&t=10907
[`io.popen`]: https://www.lua.org/manual/5.1/manual.html#pdf-io.popen
[OpenSSL]: https://slproweb.com/products/Win32OpenSSL.html
[MS Visual C++ Redist]: https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170#latest-microsoft-visual-c-redistributable-version
[ScriptsBrowser]: https://forum.farmanager.com/viewtopic.php?f=15&t=10418
[LuaBinaries]: https://github.com/FarManagerLegacy/LuaBinaries/
[`dkjson`]: http://dkolf.de/dkjson-lua/
[`json`]: https://luarocks.org/search?q=json
[lua-users wiki]: http://lua-users.org/wiki/JsonModules


Меню выбора конфигурации {#UtilitiesMenu}
========================

В комплекте идут __определения__ для ряда опробованных мной утилит/сервисов
(но легко добавить и новые).

С некоторыми соображениями по выбору конфигурации можно ознакомиться в разделе [Обзор конфигураций].

- Выбор конфигурации осуществляется через __меню__, доступное как прямо из [диалога][Диалог],
  так и отовсюду посредством макроса.  
  Выбор запоминается.
- Верхний раздел списка содержит "нативные" конфигурации, работающие с сетью средствами Lua.  
  Раздел не будет отображаться, если отсутствуют необходимые модули, см. [Установка].  
  Стандартные конфигурации (см. [обзор][Обзор конфигураций]):
  _OpenAI-compatible_, _Google Gemini_, _Cohere_, _Nexra_.
- Нижний раздел списка содержит определения, использующие внешние утилиты (см. обзор ниже).  
  По умолчанию список содержит только установленные утилиты, полный список -- по `Ctrl+H`.
  - Утилиты необходимо скачать самостоятельно (соответствующий сайт открывается по `Alt+F1` из меню).
  - Утилитам может требоваться настройка (помимо параметров в диалоге),
    подробнее см. в их собственной документации.  
    Быстрый доступ к **файлу** с настройками (если применимо) - из меню по `F4`,
    или в [диалоге][Диалог] по кнопке `[ Utility cfg ]`.
- По `Alt+F4` - быстрый доступ к файлу с __определением__ той или иной конфигурации (\*.lua.cfg).

В общем случае следует отдать предпочтение "нативным" конфигурациям, поскольку они обеспечивают больше возможностей.

Однако в некоторых случаях может оказаться проще или удобнее работать и через утилиты, например:

- если соответствующая утилита уже есть (и используется из командной строки);
- если утилита уже содержит настройки провайдеров (как `bito`, `gh models`, `tgpt`, `pytgpt`);
- если пользователю проще скачать утилиту, чем выполнить другие инструкции по [установке][Установка].


Обзор утилит
------------

- [bito] - настройка описана [тут](https://forum.farmanager.com/viewtopic.php?t=13283).  
  Недостаток: бесплатный лимит 75 сообщений в день, доступ только к BASIC-модели (gpt-4o-mini).
- [gh models] - GitHub Models extension.  
  Инструкции по установке см. на домашней странице.
  Необходим аккаунт GitHub. Действуют [лимиты](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits).
- [tgpt], [pytgpt] - не требуют предварительной настройки.  
  Недостаток: не гарантирована стабильность (иногда требуется обновление утилит).
- Прочие утилиты - [aichat], [chatgpt-cli], [mods], [sgpt] - работают с [OpenAI API] (и совместимыми).  
  Требуют задания некоторых параметров, прежде всего `apibase`, `apikey`, и `model`.
  Их значения зависят от выбранного [провайдера][Обзор конфигураций].  
  В зависимости от утилиты, параметры или надо установить через **файл** настроек (как описано выше),
  или они могут быть доступны сразу в [диалоге][Диалог],
  если они передаются как __аргументы__ командной строки, или через __переменные окружения__.  
  Для заполнения параметров в диалоге можно использовать [пресеты], идущие в комплекте (см. [обзор][Обзор конфигураций]).

[Обзор утилит]: #UtilitiesMenu
[gh models]: https://github.com/github/gh-models
[tgpt]: https://github.com/aandrew-me/tgpt
[pytgpt]: https://github.com/Simatwa/python-tgpt
[bito]: https://bito.ai/
[aichat]: https://github.com/sigoden/aichat
[chatgpt-cli]: https://github.com/kardolus/chatgpt-cli
[mods]: https://github.com/charmbracelet/mods
[sgpt]: https://github.com/tbckr/sgpt
[OpenAI API]: https://platform.openai.com/docs/api-reference


Обзор конфигураций {#Providers}
==================

Выбор модели
------------

На данный момент наиболее сильные модели это:

- `o3`, `o1` и `gpt-4o` от [OpenAI];
- `gemini-2.0-pro` от [Google];
- `claude-3.7-sonnet` от [Anthropic];
- `grok-3` от [xAI];

Из опенсорсных - все что побольше, например:

- из серии [Llama] от __Meta AI__: `llama-3.1-405b`, `llama-3.2-90b`, `llama-3.3-70b`;
- ряд моделей от китайских разработчиков также демонстрирует хорошие результаты:
  [DeepSeek], [Qwen], _Yi_ от [01.AI], [MiniMax].

Ориентироваться можно по рейтингу [ChatBot Arena](https://lmarena.ai/?leaderboard).

[OpenAI]: https://platform.openai.com/
[Google]: https://ai.google.dev/
[Anthropic]: https://www.anthropic.com/
[xAI]: https://x.ai/grok
[Llama]: https://www.llama.com/
[DeepSeek]: https://www.deepseek.com/
[Qwen]: https://qwenlm.github.io/
[01.AI]: https://www.01.ai/
[MiniMax]: https://www.minimaxi.com/en


Обзор провайдеров
-----------------

- [OpenAI] -- оригинальный разработчик _ChatGPT_.  
  Новому пользователю предоставляется кредит $5, после исчерпания которого доступно только платное использование.  
  Работа с этим апи возможна как с помощью сторонних утилит, так и с помощью "нативной" конфигурации,
  так и называющейся "_OpenAI-compatible_".
- Другие _OpenAI_-совместимые: [Mistral AI], [xAI] _Grok_, [AI21 labs] _Jamba_.  
  К этой же категории относится целый ряд провайдеров, предоставляющие доступ к OpenSource-моделям.
- Провайдеры с собственным API, такие как [Google] _Gemini_, [Anthropic] _Claude_, [Cohere] _Command_, и т.д.  
  Для поддержки в _AskAI_ требуется или соответствующая "нативная" конфигурация, или специальный
  сервис-адаптер, который будет конвертировать API в совместисый с _OpenAI_ формат.  
  Примеры таких сервисов: [openai-gemini], [openai-github-copilot], и др.

[Mistral AI]: https://mistral.ai/
[AI21 labs]: https://www.ai21.com
[Cohere]: https://cohere.com/command
[openai-gemini]: https://habr.com/ru/articles/798123/
[openai-github-copilot]: https://habr.com/ru/articles/799215/


Обзор [пресетов][Пресеты] для сервисов совместимых с [OpenAI API]
-------------------------------------------------------------------------

В комплекте со скриптом идёт набор пресетов, содержащих предварительно заданные
значения `apibase` (и начальное значение `model`).  
В большинстве случаев пользователю также требуется самостоятельно получить `apikey`,
адрес сайта для регистрации можно найти в файле пресета (открывается из списка по `F4`).

С перечисленными ниже пресетами помимо конфигурации `openai.lua.cfg` совместимы также
конфигурации некоторых утилит (кроме тех, которые хранят эти значения в собственных файлах настроек).

- Не требуют ключа (`apikey`) только эти пресеты:
   - [anyai]\: контекст лимитирован
   - `tmrace`: лимит 50 сообщений в сутки
   - [deepinfra] (всевозможные OpenSource модели): some anonymous usage allowed
   - [pollinations.ai] (OpenAI, Gemini, DeepSeek, Qwen, Mistral, Llama, [...](https://text.pollinations.ai/models))
- Для использования других надо зарегистрироваться и получить ключ.
  Следующие пресеты относятся к бесплатным сервисам (с определёнными лимитами):
   - [cloudflare] (в основном небольшие модели, но есть и `@cf/meta/llama-3.3-70b-instruct-fp8-fast`,
     `@cf/deepseek-ai/deepseek-r1-distill-qwen-32b`)
   - [cohere] (серии `command-*` и `c4ai-aya-*`)
   - [gemini] от Google
   - [github] (модели от _OpenAI_, _DeepSeek_, _Anthropic_, _Mistral_, _Meta_, _Cohere_, _AI21_, _Microsoft_ и др.)
   - [groq] (модели до 90b)
   - [mistral], [codestral]
   - [sambanova] (Llama <= 405b, DeepSeek, Qwen)
- На некоторых сервисах только часть моделей доступно бесплатно:
   - [chutes] (DeepSeek, Llama, Qwen, ...)
   - [huggingface] (бесплатно в основном небольшие модели, но есть и такие как `Qwen2.5-72B-Instruct`,
     `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B`, `CodeLlama-34b-Instruct-hf`)
   - [openrouter] (доступны такие модели как `deepseek/deepseek-r1:free`, `meta-llama/llama-3.3-70b-instruct:free`,
     ряд моделей от Google, а также множество опенсорсных моделей размером поменьше)
   - [siliconflow] (бесплатно - небольшие модели)
   - [together.ai] (бесплатно - `meta-llama/Llama-3.3-70B-Instruct-Turbo-Free`, `meta-llama/Llama-Vision-Free`,
     `deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free`)
- Некоторые сервисы дают возможность бесплатно пользоваться только сайтом, но в некоторых случаях возможно
  задействовать их приватный API (указав Cookie и/или другие требуемые данные в заголовках):
   - [cerebras] (`llama-3.3-70b`, `llama3.1-70b`, `llama3.1-8b`, `deepseek-r1-distill-llama-70b`)
   - [featherless] (бесплатно - небольшие модели)
   - [fireworks.ai] (всевозможные OpenSource-модели)
   - [lepton] (всевозможные OpenSource-модели)
- Для полноты: пресеты для некоторых сервисов, для которых доступны пробные ключи:
   - [ai21] (Jamba): $10 credit, 3mo trial
   - [deepbricks] (o1/gpt-4o/3.5/claude-3.5-sonnet/llama): allows some usage with 0 balance
   - [grok] от [xAI]
   - [hyperbolic] (OpenSource-модели: DeepSeek, Llama, Qwen): $10 credit for free trial
   - [ncompass] (OpenSource-модели: Llama, Qwen, ...): $1 free credits
   - [novita.ai] (OpenSource-модели): $0.5 credit

Кроме того:

- `copilot-`/`gemini-proxy-public` позволяют попробовать соответствующие сервисы-адаптеры, упомянутые выше.  
  Примечание: `gemini` [с некоторых пор](https://developers.googleblog.com/en/gemini-is-now-accessible-from-the-openai-library/)
  доступен и через OpenAI API.
- `keepass` позволяет держать свои собственные пресеты в базе [KeePass](https://keepass.info/).  
  Подобным образом можно организовать работу и с другими аналогичными утилитами.

[ai21]: https://www.ai21.com/jamba
[anyai]: https://api.airforce/
[cerebras]: https://cloud.cerebras.ai/
[chutes]: https://chutes.ai/app
[codestral]: https://console.mistral.ai/codestral
[cloudflare]: https://developers.cloudflare.com/workers-ai/models/
[deepbricks]: https://deepbricks.ai/pricing
[deepinfra]: https://deepinfra.com/models/text-generation
[featherless]: https://featherless.ai/models
[fireworks.ai]: https://fireworks.ai/models
[gemini]: https://ai.google.dev/gemini-api/docs/openai
[github]: https://github.com/marketplace?type=models&task=chat-completion
[grok]: https://console.x.ai/
[groq]: https://console.groq.com/playground
[huggingface]: https://huggingface.co/models?other=text-generation-inference&inference=warm
[hyperbolic]: https://app.hyperbolic.xyz/models
[lepton]: https://www.lepton.ai/playground
[mistral]: https://docs.mistral.ai/getting-started/models/models_overview/
[ncompass]: https://www.ncompass.tech/about
[novita.ai]: https://novita.ai/model-api/product/llm-api
[openrouter]: https://openrouter.ai/models?q=:free
[pollinations.ai]: https://pollinations.ai/
[sambanova]: https://cloud.sambanova.ai/pricing
[siliconflow]: https://docs.siliconflow.cn/reference/chat-completions-1
[together.ai]: https://api.together.xyz/models

- - -

**Примечание**: задача перечислить все существующих сервисы не ставилась, это попросту невозможно,
не говоря о том что каждый день могут появляться новые.

Помимо самостоятельных провайдеров, можно встретить также сервисы не вполне понятного происхождения,
не имеющие даже официального сайта. Такими в списке выше являются `anyai` и `tmrace`.

По причине их неопределённого статуса пользоваться ими следует с осторожностью, и не передавать чувствительные данные!

Подобных сервисов довольно много, некоторые например перечислены тут: [cool ai stuff!](https://cas.zukijourney.com/)

---
refsTemplate: refsBottom
links: https://github.com/FarManagerLegacy/AskAI | [Скачать](https://github.com/FarManagerLegacy/AskAI/zipball/master)
...
