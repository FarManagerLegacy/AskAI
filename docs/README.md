# Ask AI – макрос для взаимодействия с ChatGPT (и другими LLM-сервисами) в FAR

Этот макрос – дальнейшее развитие **bito.ai code assistant** ([см.](https://forum.farmanager.com/viewtopic.php?t=13283)),
с поддержкой множества LLM-сервисов.

Доступ к сервисам реализуется как посредством (произвольных) консольных утилит,
так напрямую через REST API.

Каждый из LLM-сервисов имеет свои достоинства и недостатки, [выбор](#обзор-конфигураций) остаётся за пользователем.

Макрос назначен на `Ctrl+B`. Также может быть запущен в качестве скрипта [LuaShell](https://forum.farmanager.com/viewtopic.php?f=15&t=10907).

`Ctrl+B:Double` позволяет в любой момент открыть окно с выводом повторно.

*Функции:*

- Ввод **запроса** в диалоге, ранее набранные приглашения доступны в истории поля ввода.
- Вместе с запросом передаётся **выделенный в редакторе текст**.  
  Если в запросе присутствует шаблон `{{%input%}}`, то он заменяется выделенным текстом.  
  В противном случае выделенный в редакторе текст добавляется в конец запроса.

В **диалоге** доступны такие настройки:

- Возможность работы **в единой сессии**, с учётом предыдущего контекста.  
  По умолчанию (состояние `[?]`) сессия продолжается пока открыт редактор с выводом.  
  Сессию также можно в любой момент принудительно **очистить** кнопкой “`-`”.
- **Форматирование вывода** по заданной границе, или по ширине окна (состояние `[?]`).  
  Блоки кода не форматируются.
- Установка различных **параметров** генерации (в зависимости от выбранного сервиса/утилиты).  
  Значения запоминаются в истории, и легко доступны для повторного выбора.  
  Некоторые параметры специфичны для отдельной **конфигурации**, другие могут разделяться между разными
  (посредством общей истории).
- Возможность установки **переменных окружения**, необходимых для отдельных утилит.

Кнопки:

- `[ Utility cfg ]` доступна в случае, если используемая активной конфигурацией утилита
  держит **настройки в собственном файле**; нажатие кнопки позволяет открыть его в редакторе.
- `[ Definition ]` открывает в редакторе файл **определения** активной конфигурации (\*.lua.cfg),
  например при необходимости там легко изменить набор доступных параметров.
- `[ Presets - F5 ]` позволяет подставить сразу несколько параметров набором (“пресетом”).  
  По нажатию кнопки открывается [Список пресетов](#работа-с-пресетами).
- `[ Models - F6 ]` запрашивает список **моделей** через API, если это предусмотрено конфигурацией,
  в противном случае кнопка недоступна.  
  Также фиксированный список моделей может быть уже предварительно занесён в историю поля ввода
  (актуально для некоторых пресетов и конфигураций).
- `[ Switch ]` или же повторное нажатие `Ctrl+B` позволяет переключиться на другую конфигурацию,
  открывая [Меню выбора конфигурации](#меню-выбора-конфигурации).
- `{ Go! }` запуск генерации ответа модели, вывод открывается в редакторе.

Дополнительные шорткаты:

- `Shift+F4` - задать заголовки запроса (для *OpenAI-compatible*), в виде таблицы Lua или Moonscript
  (удобно использовать *[single line table literal](https://moonscript.org/reference/#the-language/table-literals)*).
- `Shift+F5` - открыть историю поля `apibase`.
- `Shift+F6` - открыть историю списка моделей.

------------------------------------------------------------------------

Макросы, активные в *окне с выводом*:

- `Ctrl+Shift+Ins`:
  - скопировать выделенный текст, склеив свёрнутые строки обратно в параграфы;
  - при отсутствии выделения ищет и обрабатывает блок кода под курсором.
- `Alt+F2` полностью убрать форматирование (свёртку).

## Работа с пресетами

Список пресетов вызывается из [диалога](#ask-ai--макрос-для-взаимодействия-с-chatgpt-и-другими-llm-сервисами-в-far) нажатием соответствующей кнопки, хоткеем, или же по `F5`.

“Пресет” представляет собой именованный набор параметров, подставляемых в соответствующие поля диалога.  
Пресеты хранятся в файлах `*.preset` и являются Lua-файлами.

Создать новый пресет можно нажав `Shift+F4` или `Ins`.

Над пресетами в списке доступны следующие действия:

- `Enter` - заполнить поля диалога значениями из пресета.
- `F4` - открыть в редакторе.
- `F5` - скопировать, `F6` - переименовать.
- `F8` или `Del` - удалить.

В списке отображаются только пресеты, подходящие для текущей конфигурации диалога:  
если в пресете содержится параметр, не имеющий соответствия в диалоге текущей конфигурации,
то такой пресет показан не будет.

Нажатием `Ctrl+H` можно принудительно отобразить все пресеты.

См. также: обзор пресетов для сервисов совместимых с **OpenAI API** в разделе [Обзор конфигураций](#обзор-конфигураций).

# Установка

- Содержимое архива разместить в отдельной директории, где-то в `Macros/scripts`.
- Для [LuaShell](https://forum.farmanager.com/viewtopic.php?f=15&t=10907) – стандартным образом, т.е. где-то в `Macros/utils`,
  или в любой другой директории, доступной через `%PATH%`.
- Для работы с сетью непосредственно, через “нативные” конфигурации, такие как `openai.lua.cfg`,
  необходимы следующие модули:
  - `LuaSocket`, `LuaSec`: <https://github.com/FarManagerLegacy/LuaBinaries/releases>  
    и их зависимости: [OpenSSL](https://slproweb.com/products/Win32OpenSSL.html), (для некоторых билдов) [MS Visual C++ Redist](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170#latest-microsoft-visual-c-redistributable-version).
  - Практически любой JSON модуль, предоставляющий функции `encode`/`decode`.
    - По умолчанию ищется модуль с одним из имён: `cjson`, `rsjson`, `ljson`, `dkjson`, `lunajson`, или просто [`json`](https://luarocks.org/search?q=json)
      (см. также [lua-users wiki](http://lua-users.org/wiki/JsonModules)).  
      Мною тестировались [Lua CJSON](https://github.com/FarManagerLegacy/LuaBinaries/) и [`dkjson`](http://dkolf.de/dkjson-lua/).
    - Для явного указания имени модуля следует использовать опцию `json_module` в начале скрипта.  
      Её можно изменить прямо в коде, либо воспользоваться возможностями [ScriptsBrowser](https://forum.farmanager.com/viewtopic.php?f=15&t=10418)/`cfgscript`.
- Также можно работать через сторонние утилиты:
  - Для запуска утилит рекомендуется модуль [Piper](https://forum.farmanager.com/viewtopic.php?p=167895#p167895)
    (положить в `modules`).  
    В случае его отсутствия для запуска будет использована стандартная функция [`io.popen`](https://www.lua.org/manual/5.1/manual.html#pdf-io.popen), в сочетании  
    с созданием временных файлов, и перенаправлением их в стандартный ввод посредством команд shell.
  - В `%PATH%` должны быть **утилиты**, соответствующие имеющимся файлам **определений** (\*.lua.cfg),
    см. раздел [Меню выбора конфигурации](#меню-выбора-конфигурации).

## Настройка

Большая часть *конфигураций* требует задания некоторых параметров в [диалоге](#ask-ai--макрос-для-взаимодействия-с-chatgpt-и-другими-llm-сервисами-в-far).  
Наиболее важные параметры - такие как `apibase`, `apikey` и `model` - определяются выбранным [провайдером](#обзор-конфигураций).

Некоторые *утилиты* используют файл настройки, доступный как из **диалога**, так и в [списке конфигураций](#меню-выбора-конфигурации)
(подробнее см. в документации соответствующих утилит).

# Меню выбора конфигурации

В комплекте идут **определения** для ряда опробованных мной утилит/сервисов
(но легко добавить и новые).

С некоторыми соображениями по выбору конфигурации можно ознакомиться в разделе [Обзор конфигураций](#обзор-конфигураций).

- Выбор конфигурации осуществляется через **меню**, доступное как прямо из [диалога](#ask-ai--макрос-для-взаимодействия-с-chatgpt-и-другими-llm-сервисами-в-far),
  так и отовсюду посредством макроса.  
  Выбор запоминается.
- Верхний раздел списка содержит “нативные” конфигурации, работающие с сетью средствами Lua.  
  Раздел не будет отображаться, если отсутствуют необходимые модули, см. [Установка](#установка).
- Нижний раздел списка содержит определения, использующие внешние утилиты.  
  По умолчанию список содержит только установленные утилиты, полный список – по `Ctrl+H`.
  - Утилиты необходимо скачать самостоятельно (соответствующий сайт открывается по `Alt+F1` из меню).
  - Утилитам может требоваться настройка (помимо параметров в диалоге),
    подробнее см. в собственной их документации.  
    Быстрый доступ к файлу с настройками (если применимо) - `F4` в меню, или по кнопке в [диалоге](#ask-ai--макрос-для-взаимодействия-с-chatgpt-и-другими-llm-сервисами-в-far).
- По `Alt+F4` - быстрый доступ к файлу с **определением** той или иной конфигурации (\*.lua.cfg).

В общем случае следует отдать предпочтение “нативным” конфигурациям, поскольку они обеспечивают больше возможностей.

Однако в некоторых случаях может оказаться проще или удобнее работать и через утилиты, например:

- если соответствующая утилита уже есть (и используется из командной строки);
- если утилита уже содержит настройки провайдеров (как `bito`, `tgpt`, `pytgpt`);
- если пользователю проще скачать утилиту, чем выполнить другие инструкции по [установке](#установка).

## Обзор утилит

- [gh models](https://github.com/github/gh-models) - GitHub Models extension.  
  Инструкуции по установке см. на домашней странице.
  Необходим аккаунт GitHub. Действуют [лимиты](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits).
- [tgpt](https://github.com/aandrew-me/tgpt), [pytgpt](https://github.com/Simatwa/python-tgpt) - не требуют предварительной настройки.  
  Недостаток: не гарантирована стабильность (иногда требуется обновление утилит).
- [bito](https://bito.ai/) настройка описана [тут](https://forum.farmanager.com/viewtopic.php?t=13283).  
  Недостаток: бесплатный лимит 20 сообщений в день.
- Прочие утилиты - [aichat](https://github.com/sigoden/aichat), [chatgpt-cli](https://github.com/kardolus/chatgpt-cli), [mods](https://github.com/charmbracelet/mods), [sgpt](https://github.com/tbckr/sgpt) - работают с [OpenAI API](https://platform.openai.com/docs/api-reference) (и совместимыми).  
  Требуют задания некоторых параметров, прежде всего `apibase`, `apikey`, и `model`.
  Их значения зависят от выбранного [провайдера](#обзор-конфигураций).  
  В зависимости от утилиты, параметры надо установить или через файл настроек
  (`F4` в списке [выбора](#меню-выбора-конфигурации)),
  или как **аргументы** командной строки (доступные в [диалоге](#ask-ai--макрос-для-взаимодействия-с-chatgpt-и-другими-llm-сервисами-в-far)),
  или через **переменные окружения** (также доступны в [диалоге](#ask-ai--макрос-для-взаимодействия-с-chatgpt-и-другими-llm-сервисами-в-far)).

# Обзор конфигураций

## Выбор модели

На данный момент наиболее сильные модели это `o1` и `gpt-4o` от [OpenAI](https://platform.openai.com/), `gemini-1.5-pro` от [Google](https://ai.google.dev/),
`claude-3.5-sonnet` от [Anthropic](https://www.anthropic.com/), `grok-2` от [xAI](https://x.ai/grok).  
Из опенсорсных - все что побольше, например из серии [Llama](https://www.llama.com/) от **Meta AI**: `llama-3.1-405b`, `llama-3.2-90b`, …

Ориентироваться можно по рейтингу [ChatBot Arena](https://lmarena.ai/?leaderboard).

## Обзор провайдеров

- [OpenAI](https://platform.openai.com/) – оригинальный разработчик ChatGPT, `gpt-4o`, `gpt-4o-mini`.  
  Новому пользователю предоставляется кредит \$5, после исчерпания которого доступно только платное использование.  
  Работа с этим апи возможна как с помощью сторонних утилит, так и с помощью “нативной” конфигурации,
  так и называющейся “*OpenAI-compatible*”.
- Другие *OpenAI*-совместимые: [Mistral AI](https://mistral.ai/), [xAI](https://x.ai/grok) *Grok*, [AI21 labs](https://www.ai21.com) *Jamba*.  
  К этой же категории относится целый ряд провайдеров, предоставляющие доступ к OpenSource
  моделям (например таким как [Llama](https://www.llama.com/), основанным на *Llama*, и др.).
- Провайдеры с собственным API, такие как [Google Gemini](https://ai.google.dev/), [Anthropic](https://www.anthropic.com/) *Claude*, [Cohere Command R+](https://cohere.com/command), и т.д.  
  Для поддержки в *AskAI* требуется или соответствующая “нативная” конфигурация, или специальный
  сервис-адаптер, который будет конвертировать API в совместисый с *OpenAI* формат.  
  Примеры таких сервисов: [openai-gemini](https://habr.com/ru/articles/798123/), [openai-github-copilot](https://habr.com/ru/articles/799215/), и др.

## Обзор [пресетов](#работа-с-пресетами) для сервисов совместимых с [OpenAI API](https://platform.openai.com/docs/api-reference)

В комплекте со скриптом идёт набор пресетов, содержащих предварительно заданные
значения `apibase` (и начальное значение `model`).  
В большинстве случаев пользователю также требуется самостоятельно получить `apikey`,
адрес сайта для регистрации можно найти в файле пресета (открывается из списка по `F4`).

С перечисленными ниже пресетами помимо конфигурации `openai.lua.cfg` совместимы также
конфигурации некоторых утилит (кроме тех, которые хранят эти значения в собственных файлах настроек).

- Не требуют ключа (`apikey`) только эти пресеты:
  - [anyai](https://api.airforce/): контекст лимитирован
  - `tmrace`: лимит 50 сообщений в сутки
  - [deepinfra](https://deepinfra.com/models/text-generation) (всевозможные OpenSource модели): some anonymous usage allowed
- Для использования других надо зарегистрироваться и получить ключ.
  Следующие пресеты относятся к бесплатным сервисам (с определёнными лимитами):
  - [cloudflare](https://developers.cloudflare.com/workers-ai/models/) (в основном небольшие модели, но есть и `@cf/meta/llama-3.3-70b-instruct-fp8-fast`)
  - [gemini](https://ai.google.dev/gemini-api/docs/openai) от Google
  - [github](https://github.com/marketplace/models/) (включая `gpt-4o`)
  - [grok](https://console.x.ai/) от [xAI](https://x.ai/grok)
  - [groq](https://console.groq.com/playground) (модели до 90b)
  - [mistral](https://docs.mistral.ai/getting-started/models/models_overview/), [codestral](https://console.mistral.ai/codestral)
  - [sambanova](https://cloud.sambanova.ai/pricing) (Llama \<= 405b)
- На некоторых сервисах только часть моделей доступно бесплатно:
  - [huggingface](https://huggingface.co/models?other=text-generation-inference&inference=warm) (бесплатно в основном небольшие модели, но есть и такие как `CodeLlama-34b-Instruct-hf` и `Qwen2.5-72B-Instruct`)
  - [openrouter](https://openrouter.ai/models?q=:free) (бесплатно в основном небольшие модели, но доступны и такие как `lfm-40b` и `llama-3.1-405b-instruct`)
  - [siliconflow](https://docs.siliconflow.cn/reference/chat-completions-1) (бесплатно в основном небольшие модели, но доступна и `Qwen2-72B-Instruct`)
  - [together.ai](https://api.together.xyz/models) (ограниченное время бесплатна `meta-llama/Llama-Vision-Free`)
- Некоторые сервисы дают возможность бесплатно пользоваться только сайтом, но в некоторых случаях возможно
  задействовать их приватный API (указав Cookie и/или другие требуемые данные в заголовках):
  - [cerebras](https://cloud.cerebras.ai/) (`llama3.1-8b`, `llama3.1-70b`)
  - [featherless](https://featherless.ai/models) (бесплатно - небольшие модели)
  - [fireworks.ai](https://fireworks.ai/models) (всевозможные OpenSource-модели)
  - [lepton](https://www.lepton.ai/playground) (всевозможные OpenSource-модели)
- Для полноты: пресеты для некоторых сервисов, для которых доступны пробные ключи:
  - [ai21](https://www.ai21.com/jamba) (Jamba): \$10 credit, 3mo trial?
  - [deepbricks](https://deepbricks.ai/pricing) (o1/gpt-4o/3.5/claude-3.5-sonnet/llama): allows some usage with 0 balance
  - [hyperbolic](https://app.hyperbolic.xyz/models) (OpenSource-модели: DeepSeek, Llama, Qwen): \$10 credit for free trial
  - [ncompass](https://www.ncompass.tech/about) (OpenSource-модели: Llama, Qwen, …): \$100 of credit
  - [novita.ai](https://novita.ai/model-api/product/llm-api) (OpenSource-модели): \$0.5 credit

Кроме того:

- `copilot-`/`gemini-proxy-public` позволяют попробовать соответствующие сервисы-адаптеры, упомянутые выше.  
  Примечание: `gemini` [с некоторых пор](https://developers.googleblog.com/en/gemini-is-now-accessible-from-the-openai-library/)
  доступен и через OpenAI API.
- `keepass` позволяет держать свои собственные пресеты в базе [KeePass](https://keepass.info/).  
  Подобным образом можно организовать работу и с другими аналогичными утилитами.

------------------------------------------------------------------------

**Примечание**: задача перечислить все существующих сервисы не ставилась, это попросту невозможно,
не говоря о том что каждый день могут появляться новые.

Помимо самостоятельных провайдеров, можно встретить также сервисы не вполне понятного происхождения,
не имеющие даже официального сайта. Такими в списке выше являются `anyai` и `tmrace`.

По причине их неопределённого статуса пользоваться ими следует с осторожностью, и не передавать чувствительные данные!

Подобных сервисов довольно много, некоторые например перечислены тут: [cool ai stuff!](https://cas.zukijourney.com/)
