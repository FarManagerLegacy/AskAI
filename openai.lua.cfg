name = "OpenAI-compatible"

local U = ...
if not U.restapi then return end
exe = true

historyName = name

predefined = {
  --https://platform.openai.com/docs/models/overview
  model={"gpt-3.5-turbo", "gpt-4", "gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-4-turbo-preview"},
  response_format={'{ type="json_object" }'},
  role={"You are a friendly AI assistant"},
}

sets = {
  apibase = {"apikey", "model", "headers", "modelsMeta"}
}

hidden = { -- to use in presets
  "headers",
  "max_completion_tokens",
  "modelsMeta",
}

local function importArgs (args)
  local level = 2
  for i=1,debug.getinfo(level, "u").nparams do
    local name = debug.getlocal(level, i)
    debug.setlocal(level, i, args[name] or args[i])
  end
end

local function getMsgText (data)
  local msg = data.message or data.detail or data.error or data
  msg = msg.message or msg -- Openrouter error
  msg = msg.error or msg   --
  return msg.message or msg
end

local function getModels (data, meta)
  if data.modelsMeta then
    if data.modelsMeta=="none" then return end
    meta = U.obj(data.modelsMeta)
    if type(meta)~="table" then
      error "modelsMeta must be table or 'none'"
    end
  else
    meta = meta or {}
  end
  if meta.dataFn then meta.dataFn(data) end
  if data.apibase and data.apibase:find"{model}" then return end
  local client = U.restapi.OpenAI(data.apikey, data.apibase, U.obj(data.headers))
  local models, statusline, errResponse = client:models(meta.endpoint)
  if not models then
    error(U.formatErrMsg(statusline,errResponse,"\n\1\n",getMsgText))
  end
  models.filterFn = meta.filterFn
  return models
end

--https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages
return function (session, stream, context, apibase, apikey, model, temperature, role,
                logit_bias, logprobs, top_logprobs, max_tokens, max_completion_tokens, n,
                frequency_penalty, presence_penalty, response_format, seed, stop, top_p, headers, modelsMeta)
  local args = type(session)=="table" and session
  if args then importArgs(args) end
  local boolean,number,obj = U.boolean, U.number, U.obj
  if apibase then
    apibase = apibase:gsub("{model}", function() return assert(model,"model required") end)
  end
  local client = U.restapi.OpenAI(apikey, apibase, obj(headers))

  local messages = session and U.getHistory(historyName) or {}
  local data = {
    messages=messages,
    model=model,
    frequency_penalty=number(frequency_penalty),
    logit_bias=obj(logit_bias),
    logprobs=boolean(logprobs),
    top_logprobs=number(top_logprobs),
    max_tokens=number(max_tokens), --deprecated
    max_completion_tokens=number(max_completion_tokens),
    n=number(n),
    presence_penalty=number(presence_penalty),
    response_format=obj(response_format),
    seed=number(seed),
    --service_tier=
    stop=stop,
    stream=boolean(stream),
    --stream_options=
    temperature=number(temperature),
    top_p=number(top_p),

    -- OpenRouter:
    --prompt=
    --repetition_penalty=number(repetition_penalty),
    --transforms=obj(transforms)
    --models=obj(models)
    --route
    --provider
  }
  if role then
    if messages[1] and messages[1].role=="system" then
      messages[1].content = role
    else
      table.insert(messages, 1, {role="system", content=role})
    end
  end
  table.insert(messages, {role="user", content=context})
  if args and args.hook then
    data = args.hook(client,data) or data
  end
  local CONTROL = 17 --CtrlEnter
  if win.GetKeyState(CONTROL) then -- use completions endpoint
    data.messages = nil
    data.echo = true
    data.prompt = context
    local prompt,suffix = context:match"^(.-)>_<(.-)$"
    if suffix then
      data.prompt, data.suffix = prompt, suffix
    end
    --data.best_of = 2
    client.defaultEndpoint = "/completions"
  end

  return function (cb)
    local lastIdx, errStream = 0, nil
    local chunks = {}
    local function ln() return chunks[1] and "\n\n" or "" end
    local function isInteresting (reason)
      return reason and reason~="stop" and reason~="eos" and reason~="" and type(reason)=="string" -- together.ai: eos
    end
    local response,statusline,errResponse = client:generate(data, function (chunk,err,extra)
      if err then
        cb(ln()); chunks[1] = chunks[1] or ""
        errStream = err
        if type(extra)=="string" then
          err = err.." "..extra
        elseif type(extra)=="table" then
          return cb(U.formatErrMsg(err,extra,"\n",getMsgText).."\n")
        end
        return cb("Error: "..err)
      end
      local candidate = chunk.choices[1]
      if not candidate then return end
      candidate.index = candidate.index or 0
      if candidate.index~=lastIdx then
        cb("\n\n")
        lastIdx = candidate.index
      end
      if candidate.text then
        if candidate.index==0 then
          table.insert(chunks, candidate.text)
        end
        cb(candidate.text, chunk.model~=model and chunk.model)
      elseif candidate.delta and type(candidate.delta)=="table" and candidate.delta.content then
        if candidate.index==0 then
          table.insert(chunks, candidate.delta.content)
        end
        cb(candidate.delta.content, chunk.model~=model and chunk.model)
      end
      if isInteresting(candidate.finish_reason) then
        cb(ln().."finish_reason: "..candidate.finish_reason)
      end
      if U.check"Esc" then error("interrupted", 0) end
    end)

    if response==U.restapi.STREAMED then
      table.insert(messages, {role="assistant", content=table.concat(chunks)})
    elseif response then
      local cand1 = response.choices[1]
      table.insert(messages, {role="assistant", content=cand1.text or cand1.message.content})
      for i,candidate in ipairs(response.choices) do
        if i>1 then cb("\n\n") end
        cb(candidate.text or candidate.message.content)
        if isInteresting(candidate.finish_reason) then
          cb("\nfinish_reason: "..candidate.finish_reason)
        end
      end
    else
      table.remove(messages)
      if statusline~=errStream then
        cb(ln()..U.formatErrMsg(statusline,errResponse,"\n\n",getMsgText))
      end
    end
    cb()
  end
end,

getModels
