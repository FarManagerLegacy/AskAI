name = "ChatGPT CLI"
url = "https://github.com/kardolus/chatgpt-cli/releases"
--curl -L -o chatgpt-cli https://github.com/kardolus/chatgpt-cli/releases/latest/download/chatgpt-linux-amd64 && chmod +x chatgpt-cli && sudo mv chatgpt-cli /usr/local/bin/
exe = "chatgpt-cli" -- rename from chatgpt-windows-amd64.exe or whatever

local HOME = _isWindows and win.GetEnv"USERPROFILE" or "~"
local configdir = _pathjoin(HOME, ".chatgpt-cli")
config = _pathjoin(configdir, "config.yaml")

sessionFile = _pathjoin(configdir, "history", "%s.json")
clearSession = exe.." --clear-history --thread %s>nul"

env = {
  apikey = "OPENAI_API_KEY",
  apiurl = "OPENAI_URL", -- 'https://api.openai.com'
  model = "OPENAI_API_MODEL", -- 'gpt-3.5-turbo'
  role = "OPENAI_ROLE", -- 'You are a helpful assistant.'
  temperature = "OPENAI_TEMPERATURE", -- 1.0 (0..2)
  frequency_penalty = "OPENAI_FREQUENCY_PENALTY", -- 0.0 (-2.0..2.0)
  top_p = "OPENAI_TOP_P", -- 1.0
  presence_penalty = "OPENAI_PRESENCE_PENALTY", -- 0.0 (-2.0..2.0)
  session = "OPENAI_THREAD", -- 'default'
} --max_tokens, context_window, omit_history

sets = {
  apibase = {"apikey", "model"}
}

predefined = {
  effort={"", "low", "medium", "high"},
  target={""}
}
far.RecursiveSearch(configdir, "config.*.yaml", function(item)
  table.insert(predefined.target, item.FileName:match"config%.(.-)%.yaml")
end)


local function _boolean (key, value)
  return value=="true" and key or ""
end

return function (session, apibase, apikey, target, model, context_window, max_tokens,
                 temperature, top_p, frequency_penalty, presence_penalty, effort, role,
                 debug, seed, track_token_usage)
  return _pipeOut(exe, _context) {
    session and "--thread "..session or "--omit-history",
    _optional("--url", apibase and assert(apibase:match"(.+)/v1$", "only apibase ending with /v1 supported")),
    _optional("--api-key", apikey),
    _optional("--context-window", context_window),
    _optional("--effort", effort),
    _boolean("--debug", debug),
    _optional("--frequency-penalty", frequency_penalty),
    _optional("--max-tokens", max_tokens),
    _optional("--model", model),
    _optional("--presence-penalty", presence_penalty),
    _optional("--role", role),
    _optional("--seed", seed),
    _optional("--target", target),
    _optional("--temperature", temperature),
    _optional("--top-p", top_p),
    _boolean("--track-token-usage", track_token_usage),
  }
end,

--getModels
_readLines(function (data)
  return table.concat({ exe,
    "--list-models",
    _optional("--url", data.apibase and assert(data.apibase:match"(.+)/v1$", "only apibase ending with /v1 supported")),
    _optional("--api-key", data.apikey),
    _optional("--target", data.target),
  }, " ")
end, function (line)
  return line:match"^[-*] (.+)"
end)
