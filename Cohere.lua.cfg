name = "Cohere"
url = "https://coral.cohere.com/"
--https://dashboard.cohere.com/playground/chat

local U = ...
if not U.restapi then return end
exe = true

historyName = name

predefined = {
  apikey=win.GetEnv"COHERE_API_KEY",
  model={
    --https://cohere.com/command
    --"command-r", "command-r-plus",
    "command-r-plus-08-2024",
    "command-r-08-2024",
    --https://cohere.com/blog/command-r7b
    "command-r7b-12-2024",
    --https://cohere.com/blog/command-r7b-arabic
    "command-r7b-arabic-02-2025",
    --"command", "command-light", "command-nightly", "command-light-nightly",
    --https://cohere.com/research/aya
    --https://cohere.com/blog/aya23
    --https://cohere.com/blog/aya-expanse-connecting-our-world
    "c4ai-aya-expanse-8b", "c4ai-aya-expanse-32b",
    --https://cohere.com/blog/aya-vision
    "c4ai-aya-vision-8b", "c4ai-aya-vision-32b",
 },
 connectors={--test
   "",
   '{{id: "web-search"}}',
   '{{id: "web-search", options: site: "example.com"}}',
 },
 response_format={"", 'type: "json_object"'},
 safety_mode={"", "CONTEXTUAL", "STRICT", "NONE"},
}

local function getMsgText (data)
  return data.message
end

--https://docs.cohere.com/reference/chat-v1
return function (session, stream, context, apikey, model, role, connectors, --[[search_queries_only,]] temperature,
                 max_tokens, max_input_tokens, top_k, top_p, seed, stop_sequences, frequency_penalty, presence_penalty,
                 force_single_step, response_format, safety_mode)
  local client = U.restapi.LinesStream(apikey, "https://api.cohere.ai/v1", {Accept="application/json"})
  function client:is_valid (parsed) --luacheck: ignore 212/self
    return parsed.event_type
  end
  function client:is_valid_final (parsed) --luacheck: ignore 212/self
    return parsed.text
  end

  local history = session and U.getHistory(historyName) or {}
  local boolean,number,obj = U.boolean, U.number, U.obj
  local data = {
    message=context,
    stream=boolean(stream),
    model=model,
    preamble=role,
    chat_history=history[1] and history or nil,
    connectors=obj(connectors),
    --conversation_id
    --prompt_truncation
    --search_queries_only=boolean(search_queries_only),
    --documents
    --citation_quality
    temperature=number(temperature), -- 0.3
    max_tokens=number(max_tokens),
    max_input_tokens=number(max_input_tokens),
    k=number(top_k),
    p=number(top_p),
    seed=number(seed),
    stop_sequences=obj(stop_sequences),
    frequency_penalty=number(frequency_penalty),
    presence_penalty=number(presence_penalty),
    force_single_step=boolean(force_single_step),
    response_format=obj(response_format),
    safety_mode=safety_mode,
  }
  return function (cb)
    local finalResponse, streamed, errStream
    local function ln() return streamed and "\n\n" or "" end
    local response,statusline,errResponse = client:generate("/chat", data, function (chunk,err,extra)
      if err then
        cb(ln()); streamed = true
        errStream = err
        if type(extra)=="string" then
          err = err.." "..extra
        elseif type(extra)=="table" then
          return cb(U.formatErrMsg(err,extra,"\n\n",getMsgText).."\n")
        end
        cb("Error: "..err)
      elseif chunk.event_type=="stream-start" then --luacheck: ignore 542
        -- noop
      elseif chunk.event_type=="stream_end" then
        finalResponse = chunk.response.text
      elseif chunk.event_type=="text-generation" then
        cb(assert(chunk.text, "text expected"),nil)
        if U.check"Esc" then error("interrupted", 0) end
        streamed = true
      elseif chunk.event_type=="stream-end" then
        finalResponse = assert(chunk.response, "response expected")
      elseif chunk.event_type=="search-queries-generation"
          or chunk.event_type=="search-results"
          or chunk.event_type=="citation-generation" then --luacheck: ignore 542
        --le(chunk)
      elseif chunk.event_type then
        error("Unexpected event type: "..tostring(chunk.event_type))
      else
        error("Unexpected response:\n"..U.formatJson(chunk))
      end
    end)

    if response then
      if not finalResponse then
        if response==U.restapi.STREAMED then
          cb(ln().."Error: stream-end event missed")
        else
          cb(response.text)
          finalResponse = response
        end
      end
      if finalResponse then
        if finalResponse.finish_reason~="COMPLETE" then
          cb(ln().."finish_reason: "..finalResponse.finish_reason)
        end
        U.setHistory(historyName, assert(finalResponse.chat_history, "chat_history expected"))
      end
    elseif statusline~=errStream then
      cb(ln()..U.formatErrMsg(statusline,errResponse,"\n\n",getMsgText))
    end
    cb()
  end
end,

--https://docs.cohere.com/reference/list-models
function (data) -- getModels
  local client = U.restapi.LinesStream(data.apikey, "https://api.cohere.ai/v1")
  local models, statusline, errResponse = client:models("/models?endpoint=chat")
  if not models then
    error(U.formatErrMsg(statusline,errResponse,"\n\1\n",getMsgText))
  end
  return models
end
