name = "Google Gemini"
url = "https://aistudio.google.com/"

local U = ...
if not U.restapi then return end
exe = true

historyName = name

predefined = {
  api_base={
    "https://generativelanguage.googleapis.com/v1beta",
    "https://generativelanguage.googleapis.com/v1alpha",
    "https://generativelanguage.googleapis.com/v1"
  },
  model={
    "gemini-1.5-pro-latest",
    "gemini-1.5-flash-latest",
    "gemini-1.5-flash-8b-latest",
    "gemini-exp-1114",
    "gemini-exp-1121",
    "gemini-exp-1206",
    "gemini-2.0-flash-exp",
    "gemini-2.0-flash-thinking-exp",
    "learnlm-1.5-pro-experimental",
  },
  apikey=win.GetEnv"GEMINI_API_KEY",
  responseMimeType={
    "",
    "text/plain", -- (default)
    "application/json",
    "text/x.enum", --https://ai.google.dev/gemini-api/docs/file-prompting-strategies#plain_text_formats
  },
  HarmBlockThreshold={ --https://ai.google.dev/api/generate-content#HarmBlockThreshold
    "",
    "HARM_BLOCK_THRESHOLD_UNSPECIFIED",	--Threshold is unspecified.
    "BLOCK_LOW_AND_ABOVE",	--Content with NEGLIGIBLE will be allowed.
    "BLOCK_MEDIUM_AND_ABOVE",	--Content with NEGLIGIBLE and LOW will be allowed.
    "BLOCK_ONLY_HIGH",	--Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed.
    "BLOCK_NONE",	--All content will be allowed.
    "OFF",	--Turn off the safety filter.
  },
  tools={
    "",
    --https://ai.google.dev/gemini-api/docs/code-execution?lang=rest
    "codeExecution:{}",
    "googleSearch:{}",
    --https://ai.google.dev/gemini-api/docs/grounding?lang=rest
    --[[
    "{googleSearchRetrieval={
       dynamicRetrievalConfig={
         mode: MODE_UNSPECIFIED|MODE_DYNAMIC
         dynamicThreshold: number
       },
     }",
    --]]
  },
}

local function wrapCode (code, codetype)
  return ("```%s\n%s\n```"):format(codetype or "", code)
end

local function processExec (part)
  if part.executableCode then
    local info = part.executableCode
    return wrapCode(info.code, info.language)
  elseif part.codeExecutionResult then
    local info = part.codeExecutionResult
    if info.outcome=="OUTCOME_OK" then
      return wrapCode(info.output, "output")
    else
      return info.outcome
    end
  end
  return "Error: unknown part's type\n"..U.formatJson(part)
end

local function getMsgText (data)
  local msg = data.message or data.error or data
  msg = msg.error or msg
  return msg.message or msg
end

--https://ai.google.dev/gemini-api/docs/safety-settings
local HarmCategory = { --https://ai.google.dev/api/generate-content#harmcategory
  --"HARM_CATEGORY_UNSPECIFIED",	--Category is unspecified.
  "HARM_CATEGORY_HARASSMENT",	--Harasment content.
  "HARM_CATEGORY_HATE_SPEECH",	--Hate speech and content.
  "HARM_CATEGORY_SEXUALLY_EXPLICIT",	--Sexually explicit content.
  "HARM_CATEGORY_DANGEROUS_CONTENT",	--Dangerous content.
  "HARM_CATEGORY_CIVIC_INTEGRITY",	--Content that may be used to harm civic integrity.
}
--https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages
return function (session, stream, context, api_base, apikey, model, temperature, role, maxOutputTokens, candidateCount,
                 responseMimeType, responseSchema, stopSequences, tools,
                 top_p, top_k, presencePenalty, frequencyPenalty, responseLogprobs, logprobs, HarmBlockThreshold)
  local number,obj,boolean = U.number, U.obj, U.boolean
  local client = U.restapi.GoogleGemini(apikey, api_base)

  local safetySettings --https://ai.google.dev/api/generate-content#safetysetting
  if HarmBlockThreshold then
    safetySettings = {}
    for i,cat in ipairs(HarmCategory) do
      safetySettings[i] = {
        category=cat,
        threshold=HarmBlockThreshold,
      }
    end
  end

  local contents = session and U.getHistory(historyName) or {}
  local data = {
    contents=contents,
    safetySettings=safetySettings,
    systemInstruction=role and {
      parts={{text=role}},
    },
    --https://ai.google.dev/api/generate-content#generationconfig
    generationConfig={
      stopSequences=obj(stopSequences),
      responseMimeType=responseMimeType,
      --https://spec.openapis.org/oas/v3.0.3#schema
      responseSchema=obj(responseSchema), --https://ai.google.dev/gemini-api/docs/structured-output?lang=rest
      candidateCount=number(candidateCount),
      maxOutputTokens=number(maxOutputTokens),
      temperature=number(temperature),
      topP=number(top_p),
      topK=number(top_k),
      presencePenalty=number(presencePenalty), --number
      frequencyPenalty=number(frequencyPenalty), --number
      responseLogprobs=boolean(responseLogprobs),
      logprobs=number(logprobs), --integer

    },
    tools=obj(tools),
  }
  table.insert(contents, {role="user", parts={text=context}})

  return function (cb)
    local _parts = {}
    local chunks = {}
    local errStream
    local function ln() return chunks[1] and "\n\n" or "" end
    --https://ai.google.dev/api/generate-content#endpoint
    local response,statusline,errResponse = client:generate(data, model, stream, function (chunk,err,extra)
      if err then
        cb(ln()); chunks[1] = chunks[1] or ""
        errStream = err
        if type(extra)=="string" then
          err = err.." "..extra
        elseif type(extra)=="table" then
          return cb(U.formatErrMsg(err,extra,"\n\n",getMsgText).."\n")
        end
        return cb("Error: "..err)
      end
      local candidate = chunk.candidates[1]
      if not candidate then
        --https://ai.google.dev/api/generate-content#BlockReason
        local reason = chunk.promptFeedback and chunk.promptFeedback.blockReason
        if reason then
          cb(ln().."promptFeedback.blockReason: "..reason)
          --chunk.promptFeedback.safetyRatings[].blocked
          --le(chunk.promptFeedback.safetyRatings)
        end
        return
      end
      assert(not candidate.index or candidate.index==0, "Unexpected candidate index")
      local parts = candidate.content and candidate.content.parts
      if parts then
        for i,part in ipairs(parts) do
          if part.text then
            if i>1 then --gemini-2.0-flash-thinking-exp
              part.text = "\n\n|>"..part.text
            end
            table.insert(chunks, part.text)
            cb(part.text, chunk.modelVersion~=model and chunk.modelVersion)
          else
            if chunks[1] then
              table.insert(_parts, {text=table.concat(chunks)})
              chunks = {}
            end
            cb("\n"..processExec(part).."\n")
            table.insert(_parts, part)
          end
        end
      else --debug
        cb("Error: no content\n"..U.formatJson(candidate))
        --??if not candidate.safetyRatings then return end
        --todo:
        --{"citationMetadata":{"citationSources":[{"uri":"https:\/\/forum.farmanager.com\/viewtopic.php?p=171909","startIndex":5254,"endIndex":5517}]},"finishReason":"RECITATION"}
      end
      local reason = candidate.finishReason
      if reason and reason~="STOP" and type(reason)=="string" then
        cb(ln().."finishReason: "..reason)
        --le(candidate.safetyRatings)
      end
      if U.check"Esc" then error("interrupted", 0) end
    end)

    if response==U.restapi.STREAMED then
      table.insert(_parts, {text=table.concat(chunks)})
      table.insert(contents, {role="model", parts=_parts})
    elseif response then
      table.insert(contents, response.candidates[1].content)
      for i,candidate in ipairs(response.candidates) do
        local parts = candidate.content and candidate.content.parts
        if parts then
          for ii,part in ipairs(parts) do
            if part.text then
              if i>1 or ii>1 then cb("\n\n") end
              cb(part.text)
            else
              cb("\n"..processExec(part).."\n")
            end
          end
        else --debug
          cb("Error: no content\n"..U.formatJson(candidate))
        end
        local reason = candidate.finishReason
        if reason and reason~="STOP" and type(reason)=="string" then
          cb("\nfinishReason: "..reason)
          --le(candidate.safetyRatings)
        end
      end
      local reason = response.promptFeedback and response.promptFeedback.blockReason
      if reason then
        cb(ln().."promptFeedback.blockReason: "..reason)
        --response.promptFeedback.safetyRatings[].blocked
        --le(response.promptFeedback.safetyRatings)
      end
    else
      table.remove(contents)
      if statusline~=errStream then
        cb(ln()..U.formatErrMsg(statusline,errResponse,"\n\n",getMsgText))
      end
    end
    cb()
  end
end,

--https://ai.google.dev/api/models#endpoint_1
function (data) -- getModels
  local client = U.restapi.GoogleGemini(data.apikey)
  local models, statusline, errResponse = client:models()
  if not models then
    error(U.formatErrMsg(statusline,errResponse,"\n\1\n",getMsgText))
  end
  models.filterFn = function (model)
    for _,method in ipairs(model.supportedGenerationMethods) do
      if method=="generateContent" then
        return true
      end
    end
  end
  models.nameFn = function (model)
    return model.name:match"models/(.+)"
  end
  return models
end
